import streamlit as st
import pandas as pd
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
from matplotlib import colors as mcolors
from matplotlib.patches import FancyArrowPatch
import seaborn as sns
import community as community_louvain  # Certifique-se de ter isso no in√≠cio
from collections import Counter


# Configura√ß√£o da p√°gina
st.set_page_config(layout="wide", page_title="An√°lise de Redes")
st.title("üîç An√°lise e Visualiza√ß√£o de Redes")
st.markdown(
    """
Esta aplica√ß√£o analisa redes a partir de dados de relacionamento.
Carregue um arquivo CSV com colunas 'source' e 'target' para come√ßar.
"""
)

# Upload do arquivo - vers√£o com op√ß√µes
st.markdown("### üìÅ Selecione a fonte dos dados")
load_option = st.radio(
    "Escolha como deseja carregar os dados:",
    options=[
        "üì§ Upload manual (seu arquivo CSV)",
        "üåê URL do GitHub (raw)",
        "üì¶ Exemplos pr√©-configurados"
    ],
    horizontal=True,
    label_visibility="collapsed"
)

df = None

if load_option == "üì§ Upload manual (seu arquivo CSV)":
    st.markdown("#### Fa√ßa upload do seu arquivo CSV")
    uploaded_file = st.file_uploader(
        "Arraste e solte ou clique para procurar",
        type="csv",
        key="file_uploader",
        help="Formatos suportados: CSV com colunas 'source' e 'target'"
    )
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        
elif load_option == "üåê URL do GitHub (raw)":
    st.markdown("#### Carregar de URL GitHub (raw)")
    col1, col2 = st.columns([3, 1])
    with col1:
        github_url = st.text_input(
            "Cole a URL raw do GitHub",
            value="",
            placeholder="https://raw.githubusercontent.com/.../arquivo.csv",
            help="""Como obter:
            1. Acesse o arquivo no GitHub
            2. Clique em 'Raw'
            3. Copie a URL do navegador
            Exemplo: https://raw.githubusercontent.com/Croncl/projetoU3-analise-de-redes/main/distribution_relationships.csv"""
        )
    with col2:
        st.write("")  # Espa√ßamento
        st.write("")  # Espa√ßamento
        if st.button("Carregar", key="load_url_btn"):
            if github_url:
                with st.spinner("Carregando..."):
                    try:
                        if "raw.githubusercontent.com" in github_url:
                            df = pd.read_csv(github_url)
                            st.success("‚úÖ Arquivo carregado com sucesso!")
                        else:
                            st.warning("‚ö†Ô∏è Use uma URL raw do GitHub (raw.githubusercontent.com)")
                    except Exception as e:
                        st.error(f"‚ùå Erro ao carregar: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è Por favor, insira uma URL v√°lida")

else:  # Op√ß√µes pr√©-definidas
    st.markdown("#### Exemplos dispon√≠veis")
    example_option = st.selectbox(
        "Selecione um dataset de exemplo:",
        options=[
            "üìä Distribui√ß√µes (exemplo simples)",
            "üê¶ Tweets Rouanet (reduzido)",
            "ü¶Ö Tweets Rouanet (completo)"
        ],
        index=0
    )
    
    file_urls = {
        "üìä Distribui√ß√µes (exemplo simples)": "https://raw.githubusercontent.com/Croncl/projetoU3-analise-de-redes/main/distribution_relationships.csv",
        "üê¶ Tweets Rouanet (reduzido)": "https://raw.githubusercontent.com/Croncl/projetoU3-analise-de-redes/main/tweets_rouanet_graph_reduzido_filtrado.csv",
        "ü¶Ö Tweets Rouanet (completo)": "https://raw.githubusercontent.com/Croncl/projetoU3-analise-de-redes/main/tweets_rouanet_graph_filtrado.csv"
    }
    
    if st.button("Carregar Exemplo", key="load_example_btn"):
        with st.spinner(f"Carregando {example_option.split('(')[0].strip()}..."):
            try:
                df = pd.read_csv(file_urls[example_option])
                st.success(f"‚úÖ {example_option} carregado com sucesso!")
            except Exception as e:
                st.error(f"‚ùå Falha no carregamento: {str(e)}")

# Visualiza√ß√£o dos dados (para todas as op√ß√µes)
if df is not None:
    with st.expander("üîç Visualizar amostra dos dados", expanded=True):
        st.dataframe(df.head(3))
        st.caption(f"üìä Total: {len(df)} registros | üè∑Ô∏è Colunas: {', '.join(df.columns)}")
        
    # Processamento do grafo
    df.dropna(subset=["source", "target"], inplace=True)
    G = nx.from_pandas_edgelist(
        df, source="source", target="target", create_using=nx.DiGraph()
    )
    G.remove_edges_from(nx.selfloop_edges(G))

    st.success(
        f"üéâ Grafo carregado: {G.number_of_nodes()} n√≥s e {G.number_of_edges()} arestas"
    )

    # =============================================
    # M√âTRICAS ESTRUTURAIS(Sem filtros)
    # =============================================
    # TEXTOS DE AJUDA (M√©tricas Estruturais)
    help_densidade = (
        "A densidade √© a raz√£o entre o n√∫mero de arestas existentes e o n√∫mero m√°ximo poss√≠vel. "
        "Varia de 0 a 1.\n\n"
        "- 0: grafo extremamente esparso (poucas conex√µes)\n"
        "- 1: grafo completamente conectado (todos os n√≥s se conectam entre si)\n\n"
        "√ötil para entender qu√£o interligada √© a rede."
    )
    help_assortatividade = (
        "Mede a tend√™ncia de n√≥s se conectarem com outros de grau similar. "
        "Varia de -1 a +1.\n\n"
        "- Valor > 0: n√≥s com grau alto conectam-se a outros com grau alto (ex: redes sociais)\n"
        "- Valor < 0: n√≥s com grau alto conectam-se a n√≥s com grau baixo (ex: redes tecnol√≥gicas)\n"
        "- Valor ‚âà 0: conex√µes s√£o aleat√≥rias em rela√ß√£o ao grau dos n√≥s\n\n"
        "Ajuda a entender o padr√£o de conex√µes da rede."
    )
    help_clustering = (
        "Mede o grau de agrupamento (forma√ß√£o de tri√¢ngulos) entre os vizinhos de um n√≥. "
        "Varia de 0 a 1.\n\n"
        "- Valor pr√≥ximo de 1: forte tend√™ncia de formar grupos (alta coes√£o local)\n"
        "- Valor pr√≥ximo de 0: pouca ou nenhuma forma√ß√£o de grupos\n\n"
        "Comum em redes sociais e redes pequenas-mundo."
    )
    help_scc = (
        "N√∫mero de subgrafos nos quais **cada n√≥ pode alcan√ßar todos os outros seguindo a dire√ß√£o das arestas**.\n\n"
        "- Relevante em redes dirigidas (como grafos de cita√ß√µes ou hyperlinks).\n"
        "- Valor maior indica uma rede mais fragmentada em termos de alcance direcional.\n"
        "- Um √∫nico componente forte sugere alta conectividade m√∫tua.\n\n"
        "Ex: Em um SCC, se A alcan√ßa B, ent√£o B tamb√©m alcan√ßa A por algum caminho dirigido."
    )

    help_wcc = (
        "N√∫mero de subgrafos nos quais os n√≥s est√£o conectados **se ignorarmos a dire√ß√£o das arestas**.\n\n"
        "- Mede a conectividade geral da estrutura, desconsiderando direcionalidade.\n"
        "- √ötil para avaliar fragmenta√ß√£o estrutural bruta da rede.\n"
        "- Um √∫nico componente fraco indica que todos os n√≥s est√£o ligados por algum caminho (mesmo que indirecional).\n\n"
        "Ex: A pode n√£o alcan√ßar B na dire√ß√£o correta, mas ainda faz parte do mesmo grupo fraco."
    )
    help_katz = (
        "A centralidade de Katz mede a influ√™ncia de um n√≥, considerando todas as caminhadas poss√≠veis at√© ele, "
        "mas penalizando caminhos mais longos com um fator de atenua√ß√£o.\n\n"
        "- Diferente do PageRank, ela atribui import√¢ncia inclusive a conex√µes indiretas.\n"
        "- Requer um par√¢metro alfa (menor que o inverso do maior autovalor do grafo) para garantir converg√™ncia.\n\n"
        "‚ö†Ô∏è Se o grafo for grande, muito esparso ou desconexo, ou se o par√¢metro n√£o for adequado, "
        "o c√°lculo pode falhar por n√£o convergir ou por gerar n√∫meros inst√°veis, resultando em 'N/A'."
    )

    help_pagerank = (
        "O PageRank mede a import√¢ncia de um n√≥ com base na quantidade e qualidade das conex√µes recebidas.\n\n"
        "- Desenvolvido por Larry Page (Google), ele atribui maior pontua√ß√£o a n√≥s que s√£o apontados por outros n√≥s importantes.\n"
        "- √ötil para identificar n√≥s influentes em redes direcionadas.\n\n"
        "‚ö†Ô∏è Em grafos desconectados ou com estruturas degeneradas (ex: n√≥s isolados), o algoritmo pode ter dificuldade de convergir "
        "e retornar valores consistentes. Nesses casos, o resultado pode ser 'N/A'."
    )
    help_diametro = (
        "O di√¢metro √© a maior dist√¢ncia geod√©sica entre quaisquer dois n√≥s da maior componente conexa da rede.\n\n"
        "- Representa o 'pior caso' de dist√¢ncia entre pares de n√≥s.\n"
        "- Quanto menor o di√¢metro, mais 'compacta' √© a rede.\n\n"
        "‚ö†Ô∏è Se a rede n√£o for conexa (ou seja, houver n√≥s isolados ou m√∫ltiplas componentes), "
        "o di√¢metro n√£o pode ser calculado diretamente e o resultado ser√° 'N/A'."
    )
    help_caminho_medio = (
        "O comprimento m√©dio do caminho mede a m√©dia das dist√¢ncias mais curtas entre todos os pares de n√≥s "
        "da maior componente conexa da rede.\n\n"
        "- Reflete qu√£o facilmente a informa√ß√£o se espalha na rede.\n"
        "- Redes pequenas-mundo tendem a ter caminhos m√©dios curtos.\n\n"
        "‚ö†Ô∏è Se o grafo n√£o for conexo (mesmo ignorando dire√ß√µes), n√£o √© poss√≠vel calcular dist√¢ncias entre todos os pares, "
        "e o resultado ser√° 'N/A'."
    )
    help_excentricidade = (
        "A excentricidade de um n√≥ √© a maior dist√¢ncia entre ele e qualquer outro n√≥ da componente em que est√°.\n"
        "A excentricidade m√©dia considera todos os n√≥s da maior componente conexa.\n\n"
        "- Valores mais baixos indicam maior centralidade estrutural.\n"
        "- Relaciona-se com o qu√£o 'longe' um n√≥ pode estar de qualquer outro na rede.\n\n"
        "‚ö†Ô∏è Se a rede n√£o for conexa (ao menos ignorando a dire√ß√£o das arestas), a excentricidade m√©dia "
        "n√£o poder√° ser calculada e o valor ser√° 'N/A'."
    )


    def calcular_assortatividade_segura(grafo):
        """
        Calcula o coeficiente de assortatividade de forma segura, evitando erros em grafos esparsos.

        Args:
            grafo: Um grafo NetworkX (Graph ou DiGraph)

        Returns:
            float: Valor da assortatividade ou None se n√£o for poss√≠vel calcular
        """
        try:
            # Verifica se o grafo tem n√≥s suficientes e varia√ß√£o de graus
            if grafo.number_of_nodes() < 2:
                return None

            degrees = [d for _, d in grafo.degree()]
            if len(set(degrees)) < 2:  # Todos os n√≥s t√™m o mesmo grau
                return None

            return nx.degree_assortativity_coefficient(grafo)
        except (ZeroDivisionError, nx.NetworkXError):
            return None

    # =============================================
    # M√âTRICAS ESTRUTURAIS E VISUALIZA√á√ÉO EST√ÅTICA
    # =============================================
    with st.expander("üìä M√©tricas Estruturais da Rede", expanded=False):
        col1, col2 = st.columns(2)

        with col1:
            st.metric("Densidade", f"{nx.density(G):.4f}", help=help_densidade)

            assort = calcular_assortatividade_segura(G)
            st.metric(
                "Assortatividade (grau do n√≥)",
                f"{assort:.4f}" if assort is not None else "N/A",
                help=help_assortatividade,
            )

            st.metric(
                "Coef. Clustering",
                f"{nx.average_clustering(G.to_undirected()):.4f}",
                help=help_clustering,
            )

            try:
                katz = nx.katz_centrality_numpy(G)
                katz_avg = sum(katz.values()) / len(katz)
                st.metric("Centralidade de Katz (m√©dia)", f"{katz_avg:.4f}", help=help_katz)
            except Exception as e:
                st.metric("Centralidade de Katz (m√©dia)", "N/A", help=help_katz)

            try:
                pagerank = nx.pagerank(G)
                pr_avg = sum(pagerank.values()) / len(pagerank)
                st.metric("PageRank (m√©dio)", f"{pr_avg:.4f}", help=help_pagerank)
            except Exception as e:
                st.metric("PageRank (m√©dio)", "N/A", help=help_pagerank)

        with col2:
            if nx.is_directed(G):
                sccs = list(nx.strongly_connected_components(G))
                scc_count = sum(1 for c in sccs if len(c) >= 2)
                isolated_scc_count = sum(1 for c in sccs if len(c) == 1)
                st.metric("SCCs com ‚â•2 n√≥s", scc_count, help=help_scc)
                st.metric("N√≥s isolados (SCCs tamanho 1)", isolated_scc_count, help="N√≥s que n√£o fazem parte de componentes fortemente conectados com outros")
            else:
                st.metric("SCCs com ‚â•2 n√≥s", "N/A", help=help_scc)
                st.metric("N√≥s isolados (SCCs tamanho 1)", "N/A", help="N√≥s que n√£o fazem parte de componentes fortemente conectados com outros")

            st.metric(
                "Componentes Fracamente Conectados",
                nx.number_weakly_connected_components(G),
                help=help_wcc,
            )

            # Di√¢metro e comprimento m√©dio do caminho (se conexa)
            try:
                if nx.is_connected(G.to_undirected()):
                    diameter = nx.diameter(G.to_undirected())
                    avg_path = nx.average_shortest_path_length(G.to_undirected())
                    eccentricity = nx.eccentricity(G.to_undirected())
                    ecc_avg = sum(eccentricity.values()) / len(eccentricity)
                    st.metric("Di√¢metro", f"{diameter}", help=help_diametro)
                    st.metric("Caminho M√©dio", f"{avg_path:.4f}", help=help_caminho_medio)
                    st.metric("Excentricidade M√©dia", f"{ecc_avg:.2f}", help=help_excentricidade)
                else:
                    st.metric("Di√¢metro", "N/A", help=help_diametro)
                    st.metric("Caminho M√©dio", "N/A", help=help_caminho_medio)
                    st.metric("Excentricidade M√©dia", "N/A", help=help_excentricidade)
            except Exception as e:
                st.metric("Di√¢metro", "Erro", help=help_diametro)
                st.metric("Caminho M√©dio", "Erro", help=help_caminho_medio)
                st.metric("Excentricidade M√©dia", "Erro", help=help_excentricidade)
    # =============================================
    # VISUALIZA√á√ÉO EST√ÅTICA
    # =============================================

    with st.expander(
        "üìä Visualiza√ß√£o Est√°tica do Grafo (M√©tricas de Centralidade)", expanded=False
    ):
        st.markdown(
            """
        ## Compara√ß√£o Visual das M√©tricas de Centralidade
        
        Cada visualiza√ß√£o destaca os n√≥s mais importantes de acordo com diferentes m√©tricas:
        - **Tamanho do n√≥**: Proporcional √† centralidade
        - **Cor**: Escala de azul (menos central) a amarelo (mais central)
        """
        )

        # Selecionar m√©trica
        metric_option = st.selectbox(
            "Selecione a m√©trica para visualiza√ß√£o:",
            [
                "Degree Centrality",
                "Closeness Centrality",
                "Betweenness Centrality",
                "Eigenvector Centrality",
                "Strongly Connected Component",
                "Weakly Connected Component",
            ],
            key="static_viz_metric",
        )

        # Calcular centralidades com tratamento de erro robusto
        try:
            if metric_option == "Degree Centrality":
                centrality = nx.degree_centrality(G)
                title = "Degree Centrality (N√≥s mais conectados)"
            elif metric_option == "Closeness Centrality":
                centrality = nx.closeness_centrality(G)
                title = "Closeness Centrality (N√≥s que alcan√ßam outros mais rapidamente)"
            elif metric_option == "Betweenness Centrality":
                centrality = nx.betweenness_centrality(G)
                title = "Betweenness Centrality (N√≥s que atuam como pontes)"
            elif metric_option == "Eigenvector Centrality":
                try:
                    centrality = nx.eigenvector_centrality(G, max_iter=1000)
                    title = "Eigenvector Centrality (N√≥s conectados a outros importantes)"
                except nx.PowerIterationFailedConvergence:
                    st.error(
                        "N√£o foi poss√≠vel calcular Eigenvector Centrality (o algoritmo n√£o convergiu)"
                    )
                    centrality = None
            elif metric_option == "Strongly Connected Component":
                sccs = list(nx.strongly_connected_components(G))
                centrality = {node: len(c) for c in sccs for node in c}
                title = "Componentes Fortemente Conectados (tamanho do SCC de cada n√≥)"
            elif metric_option == "Weakly Connected Component":
                wccs = list(nx.weakly_connected_components(G))
                centrality = {node: len(c) for c in wccs for node in c}
                title = "Componentes Fracamente Conectados (tamanho do WCC de cada n√≥)"
        except Exception as e:
            st.error(f"Erro ao calcular {metric_option}: {str(e)}")
            centrality = None

        layout_option = st.selectbox(
            "Escolha o layout da visualiza√ß√£o",
            ["spring", "circular", "random"],
            index=0,
            help="Escolha o algoritmo de layout para distribuir os n√≥s na visualiza√ß√£o."
        )


        if centrality and len(centrality) > 0:
            # Preparar valores
            cent_values = np.array(list(centrality.values()))
            nodes_list = list(centrality.keys())

            if np.ptp(cent_values) == 0:
                st.warning(
                    f"Todos os n√≥s t√™m o mesmo valor de {metric_option.split()[0]} Centrality"
                )
                sizes = np.full_like(cent_values, 300)
                colors = np.zeros_like(cent_values)
            else:
                sizes = 10 + 150 * (cent_values - cent_values.min()) / (
                    np.ptp(cent_values) + 1e-10
                )
                colors = (cent_values - cent_values.min()) / (np.ptp(cent_values) + 1e-10)

            # Layout e figura
            k_value = 1.5 / np.sqrt(len(G))  # Valor maior ‚Üí n√≥s mais afastados
            if layout_option == "spring":
                k_value = 1.5 / np.sqrt(len(G)) if len(G) > 0 else 0.1
                pos = nx.spring_layout(G, seed=42, k=k_value, iterations=100)
            elif layout_option == "circular":
                pos = nx.circular_layout(G)
            elif layout_option == "random":
                pos = nx.random_layout(G, seed=42)


            plt.style.use("dark_background")  # Define fundo escuro

            fig = plt.figure(figsize=(12, 8), facecolor="#0D1117")
            gs = fig.add_gridspec(1, 2, width_ratios=[20, 1], wspace=0.05)
            ax = fig.add_subplot(gs[0])
            cax = fig.add_subplot(gs[1])

            ax.set_facecolor("#0D1117")
            cax.set_facecolor("#0D1117")

            nodes_draw = nx.draw_networkx_nodes(
                G,
                pos,
                node_size=sizes,
                node_color=colors,
                cmap=plt.cm.plasma,# mapa de cores
                alpha=0.9, # transpar√™ncia dos n√≥s
                ax=ax,# ax do gr√°fico principal
            )

            for u, v in G.edges():
                if u == v:
                    continue  # opcional: pula auto-la√ßos
                rad = 0.2  # quanto mais alto, mais curvado
                arrow = FancyArrowPatch(
                    posA=pos[u],
                    posB=pos[v],
                    connectionstyle=f"arc3,rad={rad}",
                    arrowstyle='-',
                    color="#BBBBBB",
                    linewidth=0.4,
                    alpha=0.5
                )
                ax.add_patch(arrow)


            # R√≥tulo dos top 10
            if np.ptp(cent_values) > 0:
                top_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:10]
                for node, _ in top_nodes:
                    x, y = pos[node]
                    ax.text(
                        x, y, str(node),
                        fontsize=8,
                        ha='center',
                        va='center',
                        bbox=dict(facecolor='black', alpha=0.7, edgecolor='none')
                    )

            # T√≠tulo e eixos
            ax.set_title(title, fontsize=14, color="white")
            ax.axis("off")

            # Barra de cor separada
            norm = plt.Normalize(vmin=cent_values.min(), vmax=cent_values.max())
            cbar = plt.colorbar(
                plt.cm.ScalarMappable(norm=norm, cmap=plt.cm.plasma),
                cax=cax
            )
            cbar.set_label("Valor de Centralidade", color="white")
            cbar.ax.yaxis.set_tick_params(color='white')
            plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color='white')

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

            # Interpreta√ß√£o e tabela
            st.markdown(
                f"""
            ### Interpreta√ß√£o:
            - **N√≥s maiores e mais amarelos**: Possuem maior {metric_option.split()[0]} centrality  
            - **N√≥s menores e mais escuros**: Possuem menor {metric_option.split()[0]} centrality  
            - **Top 10 n√≥s** est√£o rotulados com seus nomes
            """
            )

            st.markdown("### üìä Tabela de Centralidades")
            df_centrality = pd.DataFrame.from_dict(
                centrality, orient="index", columns=["Centralidade"]
            )
            st.dataframe(df_centrality.sort_values("Centralidade", ascending=False))
        else:
            st.warning(
                "N√£o foi poss√≠vel gerar a visualiza√ß√£o para esta m√©trica ou todos os n√≥s t√™m o mesmo valor."
            )

    # =============================================
    # DISTRIBUI√á√ÉO DE GRAU
    # =============================================

    with st.expander("üìà Distribui√ß√£o de Grau", expanded=False):
        plt.style.use("dark_background")  # Define fundo escuro

        fig, ax = plt.subplots(1, 2, figsize=(12, 4), facecolor="#121222")

        # Grau de entrada
        sns.histplot(
            list(dict(G.in_degree()).values()),
            bins=30,
            ax=ax[0],
            color="skyblue",
            edgecolor="#111111",
        )
        ax[0].set_title("Distribui√ß√£o do Grau de Entrada", color="white")
        ax[0].set_xlabel("Grau de entrada", color="white")
        ax[0].set_ylabel("Frequ√™ncia", color="white")
        ax[0].set_yscale("log")
        ax[0].tick_params(colors="white")

        # Grau de sa√≠da
        sns.histplot(
            list(dict(G.out_degree()).values()),
            bins=30,
            ax=ax[1],
            color="salmon",
            edgecolor="black",
        )
        ax[1].set_title("Distribui√ß√£o do Grau de Sa√≠da", color="white")
        ax[1].set_xlabel("Grau de sa√≠da", color="white")
        ax[1].set_ylabel("Frequ√™ncia", color="white")
        ax[1].set_yscale("log")
        ax[1].tick_params(colors="white")

        st.pyplot(fig)

        st.markdown(
            """
            - A distribui√ß√£o de grau mostra como os n√≥s est√£o conectados na rede.
            - Redes reais muitas vezes t√™m poucos n√≥s com alto grau e muitos com baixo grau.
            - A escala logar√≠tmica evidencia essa estrutura com cauda longa.
            """
        )

    # =============================================
    # AN√ÅLISE DE CENTRALIDADE 
    # =============================================

    with st.expander("‚≠ê An√°lise de Centralidade", expanded=False):
        st.markdown(
            """
        Compare as diferentes medidas de centralidade para identificar os n√≥s mais importantes:
        - **Degree**: N√≥s mais conectados
        - **Closeness**: N√≥s que podem alcan√ßar outros mais rapidamente
        - **Betweenness**: N√≥s que atuam como pontes
        - **Eigenvector**: N√≥s conectados a outros n√≥s importantes
        """
        )

        col1, col2 = st.columns(2)
        with col1:
            metric = st.selectbox(
                "M√©trica de Centralidade",
                ["Degree", "Closeness", "Betweenness", "Eigenvector"],
                key="centrality_metric"
            )
        with col2:
            k = st.slider("N√∫mero de n√≥s para mostrar", 1, 100, 10, key="top_k_nodes")

        # C√°lculo de centralidade com tratamento de erros
        try:
            if metric == "Degree":
                centrality = nx.degree_centrality(G)
            elif metric == "Closeness":
                centrality = nx.closeness_centrality(G)
            elif metric == "Betweenness":
                centrality = nx.betweenness_centrality(G)
            elif metric == "Eigenvector":
                centrality = nx.eigenvector_centrality(G, max_iter=1000)
        except Exception as e:
            st.error(f"Erro ao calcular {metric} centrality: {str(e)}")
            centrality = None

        if centrality:
            # Mostra tabela com top k n√≥s
            top_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:k]
            st.dataframe(pd.DataFrame(top_nodes, columns=["N√≥", "Centralidade"]))
            
            # Visualiza√ß√£o est√°tica
            st.markdown("### üìå Visualiza√ß√£o dos N√≥s Mais Centrais")
            H = G.subgraph([n for n, _ in top_nodes])
            
            # Configura√ß√£o do plot
            plt.style.use('dark_background')
            fig, ax = plt.subplots(figsize=(12, 8))
            ax.set_facecolor('#0D1117')
            
            # Layout e cores
            pos = nx.spring_layout(H, seed=42)
            node_values = [centrality[n] for n in H.nodes()]
            node_sizes = [100 + 500 * (val - min(node_values))/(max(node_values) - min(node_values)) for val in node_values]
            
            # Desenho do grafo
            nodes = nx.draw_networkx_nodes(
                H, pos,
                node_color=node_values,
                node_size=node_sizes,
                cmap=plt.cm.viridis,
                alpha=0.9,
                ax=ax
            )
            
            nx.draw_networkx_edges(
                H, pos,
                edge_color='#CCCCCC',
                width=0.4,
                alpha=0.5,
                ax=ax
            )
            
            # Adicionar labels para os top 5 n√≥s
            for node, (x, y) in pos.items():
                ax.text(x, y+0.02, node, 
                    ha='center', va='bottom', 
                    fontsize=8, color='white')
            
            # Colorbar corretamente integrada
            sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, 
                                    norm=plt.Normalize(vmin=min(node_values), 
                                                    vmax=max(node_values)))
            sm.set_array([])
            cbar = fig.colorbar(sm, ax=ax, shrink=0.5)
            cbar.set_label(f'Centralidade ({metric})', color='white')
            cbar.ax.yaxis.set_tick_params(color='white')
            
            plt.title(f"Top {k} N√≥s por {metric} Centrality", color='white')
            st.pyplot(fig)
            plt.close()
    # =============================================
    # DETEC√á√ÉO DE COMUNIDADES (VERS√ÉO CORRIGIDA)
    # =============================================

    with st.expander("üß© Detec√ß√£o de Comunidades", expanded=False):
        st.markdown(
            """
            ## Detec√ß√£o de Comunidades (Algoritmo Louvain)
            
            Grupos de n√≥s mais densamente conectados entre si do que com o resto da rede.
            """
        )

        # Converte para grafo n√£o direcionado
        G_undirected = G.to_undirected() if nx.is_directed(G) else G

        # Detecta comunidades
        partition = community_louvain.best_partition(G_undirected)
        community_sizes = Counter(partition.values())
        
        # Filtra comunidades pequenas (opcional)
        min_community_size = st.slider("Tamanho m√≠nimo da comunidade", 3, 10, 10)
        communities_to_keep = {comm for comm, size in community_sizes.items() if size >= min_community_size}
        
        # Filtra n√≥s e arestas
        nodes_to_keep = [node for node in G_undirected.nodes() if partition[node] in communities_to_keep]
        G_filtered = G_undirected.subgraph(nodes_to_keep)
        
        # Configura√ß√µes do plot
        plt.style.use('dark_background')
        fig, ax = plt.subplots(figsize=(12, 8))
        ax.set_facecolor('#121212')
        
                # Layout
        # Calcula um k adaptativo com base no n√∫mero de n√≥s (quanto mais n√≥s, mais espa√ßado)
        k_val = 1.2 / np.sqrt(G_filtered.number_of_nodes())  # experimente valores como 0.3, 0.5, 0.8 tamb√©m

        pos = nx.spring_layout(G_filtered, seed=42, k=k_val)
        
        # Usa seaborn para gerar cores das comunidades
        community_list = sorted(communities_to_keep)
        palette = sns.color_palette("hls", len(community_list))
        community_colors = {comm: mcolors.to_hex(c) for comm, c in zip(community_list, palette)}
        node_colors = [community_colors[partition[node]] for node in G_filtered.nodes()]

        # Tamanho dos n√≥s proporcional ao grau
        degrees = dict(G_filtered.degree())
        node_sizes = [50 + degrees[node]*5 for node in G_filtered.nodes()]
        
        # Desenha o grafo
        nx.draw_networkx_nodes(
            G_filtered, pos,
            node_color=node_colors,
            node_size=node_sizes,
            alpha=0.9,
            ax=ax
        )
        
        nx.draw_networkx_edges(
            G_filtered, pos,
            edge_color='#CCCCCC',
            width=0.3,
            alpha=0.3,
            ax=ax
        )
        
        # Adiciona labels para os n√≥s mais centrais
        top_degree_nodes = sorted(degrees.items(), key=lambda x: x[1], reverse=True)[:20]
        for node, _ in top_degree_nodes:
            x, y = pos[node]
            ax.text(x, y, str(node), 
                fontsize=8, 
                ha='center', 
                va='center',
                bbox=dict(facecolor='black', alpha=0.7, edgecolor='none'))
        
        # Legenda de comunidades
        legend_elements = [
            plt.Line2D([0], [0], 
                    marker='o', 
                    color='w', 
                    label=f'Comunidade {comm} ({size} n√≥s)',
                    markerfacecolor=community_colors[comm], 
                    markersize=10)
            for comm, size in sorted(community_sizes.items(), key=lambda x: x[1], reverse=True)
            if comm in communities_to_keep
        ]
        
        ax.legend(
            handles=legend_elements,
            title="Comunidades Detectadas",
            loc='upper left',
            bbox_to_anchor=(1.02, 1),  # um pouco √† direita e alinhado ao topo
            borderaxespad=0.0, # espa√ßamento entre a legenda e o gr√°fico
            frameon=True, # ativa borda
            framealpha=0.8, # transpar√™ncia da borda
            facecolor='#222222',
            edgecolor='white',
            fontsize=8
        )
        
        plt.title(
            f"Detec√ß√£o de Comunidades (Louvain) - {len(communities_to_keep)} comunidades com ‚â•{min_community_size} n√≥s",
            color='white'
        )
        plt.tight_layout()# evita corte na figura e na legenda
        st.pyplot(fig)
        plt.close()
        
        # Estat√≠sticas
        st.markdown("### üìä Estat√≠sticas das Comunidades")
        st.write(f"Total de comunidades detectadas: {len(community_sizes)}")
        st.write(f"Comunidades com ‚â•{min_community_size} n√≥s: {len(communities_to_keep)}")
        
        # Tabela de comunidades
        comm_table = pd.DataFrame(
            [(comm, size) for comm, size in community_sizes.items() if size >= min_community_size],
            columns=["Comunidade", "Tamanho"]
        ).sort_values("Tamanho", ascending=False)
        
        st.dataframe(comm_table)
